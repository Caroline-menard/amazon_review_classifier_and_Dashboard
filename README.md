<p align="right">
  <img src="https://github.com/Caroline-menard/-Caroline-menard/blob/main/logo_blanc.png?raw=true" alt="Logo Caroline M√©nard" width="120">
</p>

üá¨üáß Looking for the English version? [Click here](https://github.com/Caroline-menard/amazon_review_classifier_and_Dashboard/blob/main/README.en.md).

# Amazon Review Classifier & Dashboard

Ce projet est une application de classification automatique d‚Äôavis clients coupl√©e √† un dashboard interactif d√©velopp√© avec Streamlit. Il permet de d√©tecter et visualiser les principales typologies de probl√®mes signal√©s par les clients dans les avis Amazon.

## Origine des donn√©es

Les donn√©es proviennent d‚Äôun jeu de donn√©es public mis √† disposition par Amazon dans le cadre de son programme Amazon Customer Reviews Dataset.
Ce jeu contient plusieurs millions d‚Äôavis laiss√©s par des clients Amazon (Je n'ai utilis√© que des avis de la cat√©gorie *"beauty"*.)

üëâ üëâ Dans ce projet, un jeu de **4‚ÄØ600 avis** a √©t√© manuellement labellis√© pour entra√Æner un mod√®le de classification multi-label *(et multi-output)*.
Ce mod√®le a ensuite √©t√© utilis√© pour pr√©dire automatiquement les cat√©gories de probl√®me sur plus de **150‚ÄØ000 commentaires** suppl√©mentaires.


## Architecture g√©n√©rale du projet
Ce projet s‚Äôarticule autour d‚Äôun pipeline de classification automatique de commentaires produits, associ√© √† une interface de visualisation h√©berg√©e dans le cloud.


<p align="center">
  <img src="https://github.com/Caroline-menard/-Caroline-menard/blob/main/Capture%20d%E2%80%99e%CC%81cran%202025-05-11%20a%CC%80%2017.59.15.png?raw=true" alt="Architecture" width="380">
</p>

### Donn√©es

√Ä l'origine, l'ensemble des donn√©es (revues clients issues d'Amazon) √©tait h√©berg√© dans une base Supabase, ce qui permettait de traiter dynamiquement les pr√©dictions par lots et d'y ins√©rer les r√©sultats.
Pour garantir une meilleure stabilit√© du service et √©viter les interruptions li√©es aux quotas de la version gratuite, les donn√©es exploit√©es dans le dashboard Streamlit sont d√©sormais charg√©es localement √† partir d‚Äôun fichier .parquet, fourni dans le repository.

### Dashboard

L‚Äôinterface utilisateur est un dashboard interactif h√©berg√© sur Streamlit Cloud.
Il permet de visualiser la r√©partition des types de probl√®mes signal√©s, filtrer les donn√©es, explorer les commentaires bruts, et exporter une s√©lection.

Vous √™tes curieux ? Il est disponible ici üëâ [Voir le dashboard en ligne](https://caroline-menard-amazon-reviews-dashboard.streamlit.app/)

### Pipeline de pr√©diction

L‚Äôensemble du processus repose sur plusieurs scripts Python, activ√©s s√©quentiellement pour automatiser la pr√©diction des labels sur les avis clients :

  >**predict_batch.py :** s√©lectionne un batch de commentaires non encore labellis√©s depuis la base de donn√©es, ex√©cute la pipeline de pr√©diction, et g√©n√®re les r√©sultats.<br>
  >**etl_insert.py :** ins√®re ces r√©sultats dans la base Supabase.<br>
  >**main.py** : orchestre une session de pr√©diction compl√®te en appelant successivement predict_batch.py puis etl_insert.py.<br>
  >**batch_loop.py :** ex√©cute main.py en boucle jusqu‚Äô√† ce qu‚Äôil n‚Äôy ait plus de donn√©es √† pr√©dire. Une fois la base enti√®rement trait√©e, le processus s‚Äôarr√™te automatiquement.<br>
  >**utils.py :** regroupe l‚Äôensemble des composants du mod√®le : fonctions de pr√©traitement et extraction de features, vectorisation (TF-IDF + SVD), classifieur (XGBClassifier), et corrections post-pr√©diction.<br>

  ## Zoom sur la pipeline de prediction 

  ### Au coeur de la Pipeline
Le c≈ìur du mod√®le repose sur une pipeline Scikit-learn relativement complexe, illustr√©e ci-dessous :
<p align="center">
  <img src="https://github.com/Caroline-menard/-Caroline-menard/blob/main/pipeline.png?raw=true" alt="Architecture" width="1000">
</p>

##### Cette pipeline est encadr√©e par deux classes personnalis√©es :

 > **Preprocessor(BaseEstimator, TransformerMixin) :**<br>
    Ce pr√©processeur intervient avant la pipeline. Il concat√®ne le titre et le texte de chaque commentaire pour en faire un champ unique d‚Äôanalyse. Il s√©lectionne √©galement les colonnes pertinentes, et convertit certaines variables au bon format (bool√©en, cat√©goriel, etc.).

 > **LabelCorrection(BaseEstimator, TransformerMixin) :** <br>
    Cette √©tape, plac√©e apr√®s la pr√©diction, applique des r√®gles logiques simples pour corriger certains cas incoh√©rents :<br>
  > - Si la note est ‚â• 4 le label est corrig√© en ‚Äúaucun probl√®me‚Äù (Seul lle label retour_client est conserv√© s‚Äôil est activ√©.).<br>
  > - Si aucun label n‚Äôa √©t√© d√©tect√©, on assigne ‚Äúautre probl√®me‚Äù pour ne pas produire de sortie vide.

##### Structure interne de la pipeline 

On distingue deux grands groupes de features :

 > - Un premier groupe issu des textes (titre + commentaire), vectoris√©s avec un **TfidfVectorizer** puis r√©duits √† 20 dimensions gr√¢ce √† une d√©composition en composantes principales **(TruncatedSVD)**.<br>

 > - Un second groupe constitu√© de features construites "√† la main", via des **FunctionTransformer**.<br>
  Il s'agit notamment de d√©tecteurs de mots-cl√©s ou d'expressions r√©guli√®res li√©s √† des typologies pr√©cises de probl√®mes : retours clients, qualit√© per√ßue, effets secondaires, etc.<br>
    Ces features sont ensuite standardis√©es par un **StandardScaler**.

La sortie est ensuite transmise √† un **MultiOutputClassifier**, qui encapsule un XGBClassifier pour traiter la classification multilabel.
    
  ### Choix des hyperparam√®tres avec GridSearchCV
  Afin d‚Äôoptimiser les performances de la pipeline, une recherche sur grille (GridSearchCV) a √©t√© men√©e en validation crois√©e (cross-validation) sur l‚Äôensemble labellis√© de 4 600 commentaires.
L‚Äôobjectif √©tait de trouver la meilleure combinaison de param√®tres pour chaque √©tape du traitement de texte et du mod√®le de classification.

Les √©l√©ments suivants ont √©t√© test√©s :

#### TF-IDF Vectorizer 

  - **max_features :** nombre maximum de mots conserv√©s *(retenu : None)*

  - **min_df :** fr√©quence minimale d‚Äôapparition d‚Äôun mot *(retenu : 2)*

  - **ngram_range :** trigrammes , bigrammes test√©s en plus des unigrams *( retenu : (1, 3))*

#### R√©duction de dimension (SVD) 

- **n_components :** nombre de dimensions retenues *(retenu : 20 )* 

#### Mod√®les test√©s 
>*Recherche des hyperparam√®tres du mod√®le d‚Äôapprentissage, comme max_depth, learning_rate, ou n_estimators...*
 - RandomForestClassifier

 - HistGradientBoostingClassifier

 - ‚úÖ XGBoostClassifier *(retenu pour la suite)*

La grille a √©t√© explor√©e avec une validation crois√©e √† 3 plis (cv=3) et un scoring bas√© sur le F1-micro, particuli√®rement adapt√© aux t√¢ches multi-label.

   **Score moyen obtenu :** **0.7615**
    
  Ce score est consid√©r√© comme honorable compte tenu :

  - De la nature multi-label du probl√®me (chaque avis pouvant relever de plusieurs probl√©matiques),

  - Ainsi que de la variabilit√© des textes, souvent r√©dig√©s par des particuliers dans un langage non standardis√©.

>*Un extrait du notebook **GridSearchCV.ipynb est disponible** dans le d√©p√¥t pour consultation.*


## Le dashboard avec streamlit
L‚Äôapplication Streamlit comprend quatre pages :

  > - Une page d‚Äôaccueil pr√©sentant des informations g√©n√©rales et quelques graphiques cl√©s.<br>
  > - Une vue d‚Äôensemble de l‚Äô√©volution des probl√®mes signal√©s dans le temps.<br>
  > - Un zoom sur les produits les plus concern√©s par type de probl√®me.<br>
  > - Une page d‚Äôexport, qui permet de t√©l√©charger une s√©lection de commentaires selon les filtres choisis (en excel ou csv au choix)

Je n‚Äôen dis pas plus‚Ä¶
‚û°Ô∏è Pour tester le dashboard en ligne, rendez-vous ici : [Voir le dashboard en ligne](https://caroline-menard-amazon-reviews-dashboard.streamlit.app/)

**‚ö†Ô∏è L'application peut mettre quelques secondes √† se charger si elle √©tait en veille (comportement normal avec la version gratuite de Streamlit Cloud).**

<p align="center">
  <img src="https://github.com/Caroline-menard/-Caroline-menard/blob/main/dashboard_vue.png?raw=true" alt="Architecture" width="1000">
</p>

## Installation et lancement:
Python 3.9.12 recommand√©.

**Se placer √† la racine du dossier `my_app`**

**Installation des requirements**
    `pip install -r requirements.txt`

**Demarrage du dashboard:**
    `streamlit run Page_accueil.py`
